{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07lpKvsby1iD"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "random.seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGDwAO2thwle"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import random\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWfDGsJHzU6H"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PawaqhjQzLQl"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/fulldata.csv\",index_col=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BtF7rYPke7Ts"
   },
   "outputs": [],
   "source": [
    "x = data.drop(['label'], axis = 1)\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM5M88IWxn1X"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(y),x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "or9foddVmy3n"
   },
   "outputs": [],
   "source": [
    "!pip install -U imbalanced-learn\n",
    "!pip install -U scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJqn9OYOsKBU"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = StandardScaler()\n",
    "X= pd.DataFrame(scaler.fit_transform(x))\n",
    "X.columns=x.columns\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "Y=le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eF6YBUKlxeaZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "X_train, X_test, y_train, y_test=  train_test_split(X,Y,stratify=Y,test_size=0.2)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AP2OHVtl32l"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0638cZbUR9S"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import silhouette_score\n",
    "# fit model and predict clusters\n",
    "dta1_x=X_train[(y_train == 1)]\n",
    "dta0_x=X_train[(y_train == 0)]\n",
    "range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "silhouette_avg = []\n",
    "for num_clusters in range_n_clusters: \n",
    "  # initialise kmeans\n",
    "  kmeans = KMeans(n_clusters=num_clusters)\n",
    "  kmeans.fit(dta1_x)\n",
    "  cluster_labels = kmeans.labels_\n",
    "\n",
    "  # silhouette score\n",
    "  silhouette_avg.append(silhouette_score(dta1_x, cluster_labels))\n",
    "plt.plot(range_n_clusters,silhouette_avg,'bx-')\n",
    "for i, txt in enumerate(range_n_clusters):\n",
    "    plt.annotate('$k={}$'.format(txt),(range_n_clusters[i], silhouette_avg[i]))\n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Silhouette score') \n",
    "#plt.title('Silhouette analysis For Optimal k')\n",
    "from google.colab import files\n",
    "plt.savefig(\"fig2.png\")\n",
    "files.download(\"fig2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fASsmGwpX4lB"
   },
   "outputs": [],
   "source": [
    "#Proposed method\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot\n",
    "from sklearn.feature_selection import f_classif,SelectFpr\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from numpy import sqrt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import *\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "rus= RandomUnderSampler(random_state=1)\n",
    "scaler = StandardScaler()\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "model = KMeans(n_clusters=2)\n",
    "# fit model and predict clusters\n",
    "dta1_x=X_train[(y_train == 1)]\n",
    "dta0_x=X_train[(y_train == 0)]\n",
    "yhat = model.fit_predict(dta1_x)\n",
    "# retrieve unique clusters\n",
    "clusters = unique(yhat)\n",
    "twod_list1 = [] \n",
    "for i in unique(yhat):\n",
    "  clust_x=dta1_x.iloc[where(yhat == i)]\n",
    "  dfX=pd.concat([clust_x,dta0_x], axis=0).reset_index(drop=True)\n",
    "  #Creating balanced dataset\n",
    "  dfY=pd.DataFrame(np.append(np.ones(clust_x.shape[0]),np.zeros(dta0_x.shape[0])))\n",
    "  #Balancing dataset using undersampling\n",
    "  dfXX, dfYY = rus.fit_resample(dfX, dfY[0].values)\n",
    "  DFXX= pd.DataFrame(scaler.fit_transform(dfXX))\n",
    "  DFXX.columns=dfXX.columns\n",
    "  le.fit(dfYY)\n",
    "  DFYY=le.transform(dfYY) \n",
    "  #Feature selection from balanced data\n",
    "  selector = SelectFpr(alpha=0.05)\n",
    "  selector.fit(DFXX,DFYY)\n",
    "  feature_imp=DFXX.columns[selector.get_support(indices=False)]\n",
    "  twod_list1.append(feature_imp)  \n",
    "\n",
    "flat_list = [item for sublist in twod_list1 for item in sublist]\n",
    "# getting the elements frequencies using Counter class\n",
    "elements_count = Counter(np.array(flat_list))\n",
    "# Union of features\n",
    "inter={k for (k,v) in elements_count.items() if v > 0}\n",
    "\n",
    "X_train111=X_train[inter]\n",
    "y_train1=y_train\n",
    "X_test1=X_test[inter]\n",
    "\n",
    "#Classification\n",
    "\n",
    "clf1 = LogisticRegression(class_weight='balanced').fit(X_train111, y_train1)\n",
    "clf11 = LogisticRegression().fit(X_train111, y_train1)\n",
    "clf2 = RandomForestClassifier(class_weight='balanced').fit(X_train111, y_train1)\n",
    "clf3 = svm.SVC(class_weight='balanced',probability=True).fit(X_train111, y_train1)\n",
    "clf4 = CalibratedClassifierCV(base_estimator=svm.LinearSVC(class_weight='balanced'), cv=5).fit(X_train111, y_train1)\n",
    "clf44 = CalibratedClassifierCV(base_estimator=svm.LinearSVC(), cv=5).fit(X_train111, y_train1)\n",
    "clf5 = VotingClassifier(estimators=[('lr', clf11), ('gnb', clf44)],voting='soft').fit(X_train111, y_train1)\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4,clf5], ['Logistic Regression', 'Random Forest', 'SVMR','SVML','Ensemble']):\n",
    "  # define the evaluation method\n",
    "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "  # evaluate the model on the dataset\n",
    "  n_scores = cross_val_score(clf, X_train111, y_train1, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "  # report performance\n",
    "  print('Mean AUC: %.3f (%.3f) [%s]' % (mean(n_scores), std(n_scores), label))\n",
    "  y_pred=clf.predict(X_test1)\n",
    "  print(\"Accuracy\",accuracy_score(y_test, y_pred),label)\n",
    "  print(\"Precision\", precision_score(y_test, y_pred),label)\n",
    "  sensitivity=recall_score(y_test, y_pred)\n",
    "  print(\"recall/sensitivity\",sensitivity,label)\n",
    "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "  specificity = tn / (tn+fp)\n",
    "  print(\"GMean\",sqrt(sensitivity*specificity),label)\n",
    "  print(\"F1 score\",f1_score(y_test, y_pred),label)\n",
    "  print(\"AUC:\",metrics.roc_auc_score(y_test, clf.predict_proba(X_test1)[:,1]),label)\n",
    "  print(\"################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jgqPUOIKTEFX"
   },
   "outputs": [],
   "source": [
    "#without clustering only feature selection from imbalanced data\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "selector = SelectFpr(alpha=0.05)\n",
    "X_train11=selector.fit_transform(X_train,y_train)\n",
    "y_train1=y_train\n",
    "X_test11=selector.transform(X_test)\n",
    "X_train11.shape,y_train1.shape,X_test11.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wXTLmrtUaoV"
   },
   "outputs": [],
   "source": [
    "#From balanced data without clustering\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "from sklearn.feature_selection import f_classif,SelectFpr\n",
    "from imblearn.over_sampling import SMOTE, ADASYN,RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler,TomekLinks,NearMiss\n",
    "import collections\n",
    "rus= SMOTE(random_state=1)\n",
    "#rus=TomekLinks()\n",
    "scaler = StandardScaler()\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "dfXX, dfYY = rus.fit_resample(X_train, y_train)\n",
    "DFXX= pd.DataFrame(scaler.fit_transform(dfXX))\n",
    "DFXX.columns=dfXX.columns\n",
    "le.fit(dfYY)\n",
    "DFYY=le.transform(dfYY) \n",
    "\n",
    "selector = SelectFpr(alpha=0.05)\n",
    "selector.fit(DFXX,DFYY)\n",
    "feature_imp=DFXX.columns[selector.get_support(indices=False)]\n",
    "X_train11=DFXX[feature_imp]\n",
    "y_train1=DFYY\n",
    "X_test11=X_test[feature_imp]\n",
    "X_train11.shape,y_train1.shape,X_test11.shape,y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsRvpyzfC9-N"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from numpy import sqrt\n",
    "X_train111=X_train11\n",
    "X_test1=X_test11\n",
    "clf1 = LogisticRegression(class_weight='balanced').fit(X_train111, y_train1)\n",
    "clf11 = LogisticRegression().fit(X_train111, y_train1)\n",
    "clf2 = RandomForestClassifier(class_weight='balanced').fit(X_train111, y_train1)\n",
    "clf3 = svm.SVC(class_weight='balanced',probability=True).fit(X_train111, y_train1)\n",
    "clf4 = CalibratedClassifierCV(base_estimator=svm.LinearSVC(class_weight='balanced'), cv=5).fit(X_train111, y_train1)\n",
    "clf44 = CalibratedClassifierCV(base_estimator=svm.LinearSVC(), cv=5).fit(X_train111, y_train1)\n",
    "clf5 = VotingClassifier(estimators=[('lr', clf11), ('gnb', clf44)],voting='soft').fit(X_train111, y_train1)\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4,clf5], ['Logistic Regression', 'Random Forest', 'SVMR','SVML','Ensemble']):\n",
    "  # define the evaluation method\n",
    "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "  # evaluate the model on the dataset\n",
    "  n_scores = cross_val_score(clf, X_train111, y_train1, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "  # report performance\n",
    "  print('Mean AUC: %.3f (%.3f) [%s]' % (mean(n_scores), std(n_scores), label))\n",
    "  y_pred=clf.predict(X_test1)\n",
    "  #plot_confusion_matrix(clf,X_test3, y_test)\n",
    "  print(\"Accuracy\",accuracy_score(y_test, y_pred),label)\n",
    "  print(\"Precision\", precision_score(y_test, y_pred),label)\n",
    "  sensitivity=recall_score(y_test, y_pred)\n",
    "  print(\"recall/sensitivity\",sensitivity,label)\n",
    "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "  specificity = tn / (tn+fp)\n",
    "  print(\"GMean\",sqrt(sensitivity*specificity),label)\n",
    "  print(\"F1 score\",f1_score(y_test, y_pred),label)\n",
    "  print(\"AUC:\",metrics.roc_auc_score(y_test, clf.predict_proba(X_test1)[:,1]),label)\n",
    "  print(\"################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wHTF81Ifu1ux"
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from numpy import sqrt\n",
    "X_train111=X_train11\n",
    "X_test1=X_test11\n",
    "clf1 = LogisticRegression().fit(X_train111, y_train1)\n",
    "clf11 = LogisticRegression().fit(X_train111, y_train1)\n",
    "clf2 = RandomForestClassifier().fit(X_train111, y_train1)\n",
    "clf3 = svm.SVC(probability=True).fit(X_train111, y_train1)\n",
    "clf4 = CalibratedClassifierCV(base_estimator=svm.LinearSVC(), cv=5).fit(X_train111, y_train1)\n",
    "clf44 = CalibratedClassifierCV(base_estimator=svm.LinearSVC(), cv=5).fit(X_train111, y_train1)\n",
    "clf5 = VotingClassifier(estimators=[('lr', clf11), ('gnb', clf44)],voting='soft').fit(X_train111, y_train1)\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4,clf5], ['Logistic Regression', 'Random Forest', 'SVMR','SVML','Ensemble']):\n",
    "  # define the evaluation method\n",
    "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "  # evaluate the model on the dataset\n",
    "  n_scores = cross_val_score(clf, X_train111, y_train1, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "  # report performance\n",
    "  print('Mean AUC: %.3f (%.3f) [%s]' % (mean(n_scores), std(n_scores), label))\n",
    "  y_pred=clf.predict(X_test1)\n",
    "  print(\"Accuracy\",accuracy_score(y_test, y_pred),label)\n",
    "  print(\"Precision\", precision_score(y_test, y_pred),label)\n",
    "  sensitivity=recall_score(y_test, y_pred)\n",
    "  print(\"recall/sensitivity\",sensitivity,label)\n",
    "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "  specificity = tn / (tn+fp)\n",
    "  print(\"GMean\",sqrt(sensitivity*specificity),label)\n",
    "  print(\"F1 score\",f1_score(y_test, y_pred),label)\n",
    "  print(\"AUC:\",metrics.roc_auc_score(y_test, clf.predict_proba(X_test1)[:,1]),label)\n",
    "  print(\"################################################\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "featureSubset5_Final.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
